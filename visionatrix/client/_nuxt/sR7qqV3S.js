import{_ as de}from"./BZuZDTXQ.js";import{a as ce,_ as me}from"./8GsV2QyO.js";import{a as _e,_ as pe}from"./BWgXH-KU.js";import{_ as ve,a as fe}from"./DaEqC5Uo.js";import{f as ye,u as ge,z as be,y as ke,q as he,S as Ve,T as we,B as b,v as H,g as xe,x as E,C as Me,i as _,w as a,A as Ue,o as u,a as i,b as n,p as t,c as w,k as m,d as r,m as Ae,P as S,t as d,l as Ce,j as Re,D as x,Q as Se,F as ze,r as Be,J as Te,s as D}from"./BSNiacP0.js";import{a as Ne,_ as We}from"./DtQwK8Rm.js";import"./Dgxc7jlx.js";const Ee={class:"flex flex-col md:flex-row"},De={class:"px-5 md:w-4/5"},Fe={key:0},Le={class:"flex w-full items-center my-2"},Oe={class:"flex flex-col lg:flex-row px-3 py-3.5 border-b border-gray-200 dark:border-gray-700"},Pe={class:"flex"},Ie={key:0,class:"flex flex-col md:flex-row items-center"},$e={class:"p-4 overflow-y-auto relative"},Ge={class:"text-sm text-slate-500"},je={key:0},Ye={class:"flex items-center w-full"},qe={class:"flex w-full items-center my-2"},Je={key:2,class:"flex w-full items-center my-2"},He={class:"flex items-center w-full"},Ke={class:"flex items-center w-full"},Qe={class:"flex justify-end my-4"},Ze={key:0},Xe={class:"p-4 flex flex-wrap max-w-64 max-h-60 overflow-y-auto"},it=ye({__name:"workers",setup(et){ge({title:"Workers - Visionatrix",meta:[{name:"description",content:"Workers - Visionatrix"}]});const k=be(),c=ke(),K=he();Ve(()=>{k.startPolling()}),we(()=>{k.stopPolling()});const F=[{id:"actions",label:"Actions",sortable:!1},{id:"worker_status",label:"Worker status",sortable:!0},{id:"federated",label:"Federated",sortable:!0},{id:"busy",label:"Busy",sortable:!0},{id:"worker_id",label:"Worker ID"},{id:"worker_version",label:"Worker version",sortable:!0},{id:"last_seen",label:"Last seen",sortable:!0},{id:"tasks_to_give",label:"Tasks to give",sortable:!1},{id:"os",label:"OS",sortable:!0},{id:"version",label:"Python Version",sortable:!0},{id:"device_name",label:"Device name"},{id:"device_type",label:"Device type",sortable:!0},{id:"vram_total",label:"VRAM total",sortable:!0},{id:"vram_free",label:"VRAM free",sortable:!0},{id:"torch_vram_total",label:"Torch VRAM total",sortable:!0},{id:"torch_vram_free",label:"Torch VRAM free",sortable:!0},{id:"ram_total",label:"RAM total",sortable:!0},{id:"ram_free",label:"RAM free",sortable:!0},{id:"smart_memory",label:"Smart memory",sortable:!0},{id:"cache_type",label:"Cache type",sortable:!0},{id:"cache_size",label:"Cache size",sortable:!0},{id:"vae_cpu",label:"VAE CPU",sortable:!0},{id:"reserve_vram",label:"Reserve VRAM (GB)",sortable:!0}],z=F.map(o=>({key:o.id,label:o.label,sortable:o.sortable||!1,class:""})),G=localStorage.getItem("selectedColumns");let L=null;if(G!==null){const o=JSON.parse(G);L=z.filter(e=>o.includes(e.key)),L.sort(j)}const M=b(L||[...z]);H(M,o=>{localStorage.setItem("selectedColumns",JSON.stringify(Object.values(z).filter(e=>o.includes(e)).map(e=>e.key))),o.sort(j)});function j(o,e){return F.findIndex(f=>f.id===o.key)-F.findIndex(f=>f.id===e.key)}const B=xe(),O=E(()=>[...B.$state.flows_installed,...B.$state.flows_available].map(o=>({label:o.display_name,value:o.name}))),y=b([]);Me(()=>{if(B.flows.length===0){B.fetchFlows().then(()=>{y.value=[...O.value]});return}y.value=[...O.value]});const Q=E(()=>y.value.length===0?"All":y.value.length),T=b(!1);function Z(){T.value=!0,Promise.all(g.value.filter(o=>o.federated_instance_name==="").map(o=>k.setTasksToGive(o.worker_id,y.value.map(e=>e.value)))).then(()=>{D().add({title:"Tasks to give updated",description:"Tasks to give updated successfully"}),g.value=[]}).catch(()=>{D().add({title:"Failed to update tasks to give",description:"Try again"})}).finally(()=>{T.value=!1,k.loadWorkers()})}const U=b(""),P=E(()=>k.$state.workers),X=E(()=>P.value.filter(o=>Object.values(o).some(e=>String(e).toLowerCase().includes(U.value.toLowerCase()))));function Y(o){const e=new Date(o.last_seen.includes("Z")?o.last_seen:o.last_seen+"Z");return new Date().getTime()-e.getTime()<=60*5*1e3?"Online":"Offline"}const g=b([]);H(P,o=>{if(g.value.length>0){const e=g.value.map(f=>f.worker_id);g.value=o.filter(f=>e.includes(f.worker_id))}});const ee=["smart_memory","cache_type","cache_size","vae_cpu","reserve_vram"],q=b(!1);function te(){q.value=!0,c.saveChanges(ee).finally(()=>{q.value=!1})}const A=b(!1),s=b(null),le=o=>{s.value=o,A.value=!0},J=()=>{A.value=!1,s.value=null},I=b(!1),ae=()=>{s.value&&(I.value=!0,k.updateWorkerOptions(s.value.worker_id,{smart_memory:s.value.smart_memory??null,cache_type:s.value.cache_type??null,cache_size:s.value.cache_size??null,vae_cpu:s.value.vae_cpu??null,reserve_vram:s.value.reserve_vram??null}).then(()=>{D().add({title:"Worker options updated",description:"Worker options updated successfully"}),k.loadWorkers()}).catch(()=>{D().add({title:"Failed to update worker options",description:"Try again"})}).finally(()=>{I.value=!1,J()}))};return(o,e)=>{const f=de,$=ce,N=_e,h=me,W=ve,C=pe,v=Ae,oe=Ce,R=fe,se=Ne,V=Re,ne=Te,re=Se,ie=We,ue=Ue;return u(),_(ue,{class:"lg:h-dvh"},{default:a(()=>[i("div",Ee,[n(f,{links:t(c).links,class:"md:w-1/5"},null,8,["links"]),i("div",De,[e[30]||(e[30]=i("h2",{class:"mb-3 text-xl"},"Workers",-1)),t(K).isAdmin?(u(),w("div",Fe,[n($,{class:"mb-3",label:"Default Workers settings"}),n(h,{size:"md",class:"py-3",label:"Smart memory",description:"When disabled forces ComfyUI to aggressively offload to regular RAM instead of keeping models in VRAM when it can."},{default:a(()=>[n(N,{modelValue:t(c).settingsMap.smart_memory.value,"onUpdate:modelValue":e[0]||(e[0]=l=>t(c).settingsMap.smart_memory.value=l),color:"primary",class:"py-3",label:"Enable smart memory"},null,8,["modelValue"])]),_:1}),n(h,{size:"md",class:"py-3",label:"Cache type"},{description:a(()=>e[22]||(e[22]=[i("p",null,[r(" Classic - Use the old style (aggressive) caching. "),i("br"),r(" LRU - Use LRU caching with a maximum of N node results cached. May use more RAM/VRAM. "),i("br"),r(" None - Reduced RAM/VRAM usage at the expense of executing every node for each run. "),i("br")],-1)])),default:a(()=>[i("div",Le,[n(W,{modelValue:t(c).settingsMap.cache_type.value,"onUpdate:modelValue":e[1]||(e[1]=l=>t(c).settingsMap.cache_type.value=l),class:"w-fit",placeholder:"Select cache type","value-attribute":"value",options:t(c).settingsMap.cache_type.options},null,8,["modelValue","options"])]),t(c).settingsMap.cache_type.value==="lru"?(u(),_(C,{key:0,modelValue:t(c).settingsMap.cache_size.value,"onUpdate:modelValue":e[2]||(e[2]=l=>t(c).settingsMap.cache_size.value=l),type:"number",class:"w-fit",min:"1",onChange:e[3]||(e[3]=()=>{t(c).settingsMap.cache_size.value=t(c).settingsMap.cache_size.value.toString()})},null,8,["modelValue"])):m("",!0)]),_:1}),n(h,{size:"md",class:"py-3",label:"VAE cpu",description:"Run the VAE on the CPU."},{default:a(()=>[n(N,{modelValue:t(c).settingsMap.vae_cpu.value,"onUpdate:modelValue":e[4]||(e[4]=l=>t(c).settingsMap.vae_cpu.value=l),color:"primary",class:"py-3",label:"VAE on CPU"},null,8,["modelValue"])]),_:1}),n(h,{size:"md",class:"py-3",label:"Reserve VRAM",description:"Amount of VRAM in GB to reserve for use by other software (total VRAM = total VRAM - reserve VRAM)."},{default:a(()=>[n(C,{modelValue:t(c).settingsMap.reserve_vram.value,"onUpdate:modelValue":e[5]||(e[5]=l=>t(c).settingsMap.reserve_vram.value=l),type:"number",min:"0",step:"0.1",class:"w-fit"},null,8,["modelValue"])]),_:1}),n(v,{class:"mt-3",icon:"i-heroicons-check-16-solid",loading:t(I),onClick:te},{default:a(()=>e[23]||(e[23]=[r(" Save ")])),_:1,__:[23]},8,["loading"])])):m("",!0),n($,{class:"my-3"}),i("div",Oe,[i("div",Pe,[n(W,{modelValue:t(M),"onUpdate:modelValue":e[6]||(e[6]=l=>S(M)?M.value=l:null),class:"mr-3",options:t(z),multiple:""},null,8,["modelValue","options"]),n(C,{modelValue:t(U),"onUpdate:modelValue":e[7]||(e[7]=l=>S(U)?U.value=l:null),placeholder:"Filter workers..."},null,8,["modelValue"])]),t(g).length>=1?(u(),w("div",Ie,[n(W,{modelValue:t(y),"onUpdate:modelValue":e[8]||(e[8]=l=>S(y)?y.value=l:null),searchable:"",class:"mr-3 my-3 lg:mx-3 lg:my-0 w-full max-w-64 min-w-64",options:t(O),multiple:""},{label:a(()=>[i("span",null,"Tasks to give ("+d(t(Q))+")",1)]),_:1},8,["modelValue","options"]),n(oe,{text:"Flows available for worker to get tasks"},{default:a(()=>[n(v,{icon:"i-heroicons-check-16-solid",variant:"outline",color:"cyan",size:"sm",loading:t(T),onClick:Z},{default:a(()=>e[24]||(e[24]=[r(" Update tasks to give ")])),_:1,__:[24]},8,["loading"])]),_:1}),n(v,{icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[9]||(e[9]=()=>{y.value=[]})})])):m("",!0)]),n(se,{modelValue:t(A),"onUpdate:modelValue":e[20]||(e[20]=l=>S(A)?A.value=l:null),transition:!1},{default:a(()=>{var l;return[i("div",$e,[e[28]||(e[28]=i("h2",{class:"font-bold"},"Individual worker configuration options",-1)),i("p",Ge,d((l=t(s))==null?void 0:l.worker_id),1),t(s)?(u(),w("div",je,[n(h,{size:"md",class:"py-3",label:"Smart memory",description:"When disabled forces ComfyUI to aggressively offload to regular RAM instead of keeping models in VRAM when it can."},{default:a(()=>[t(s).smart_memory===null?(u(),_(R,{key:0,color:"cyan",variant:"soft",title:"Not set",class:"mb-2"})):m("",!0),i("div",Ye,[n(N,{modelValue:t(s).smart_memory,"onUpdate:modelValue":e[10]||(e[10]=p=>t(s).smart_memory=p),color:"primary",class:"py-3",label:"Enable smart memory"},null,8,["modelValue"]),t(s).smart_memory?(u(),_(v,{key:0,icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[11]||(e[11]=()=>{t(s)&&(t(s).smart_memory=null)})})):m("",!0)])]),_:1}),n(h,{size:"md",class:"py-3",label:"Cache type"},{description:a(()=>e[25]||(e[25]=[i("p",null,[r(" Classic - Use the old style (aggressive) caching. "),i("br"),r(" LRU - Use LRU caching with a maximum of N node results cached. May use more RAM/VRAM. "),i("br"),r(" None - Reduced RAM/VRAM usage at the expense of executing every node for each run. "),i("br")],-1)])),default:a(()=>[t(s).cache_type===null?(u(),_(R,{key:0,color:"cyan",variant:"soft",title:"Not set",class:"mb-2"})):m("",!0),i("div",qe,[n(W,{modelValue:t(s).cache_type,"onUpdate:modelValue":e[12]||(e[12]=p=>t(s).cache_type=p),class:"w-fit",placeholder:"Select cache type","value-attribute":"value",options:t(c).settingsMap.cache_type.options},null,8,["modelValue","options"]),t(s).cache_type!==null?(u(),_(v,{key:0,icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[13]||(e[13]=()=>{t(s)&&(t(s).cache_type=null)})})):m("",!0)]),t(s).cache_type==="lru"&&t(s).cache_size===null?(u(),_(R,{key:1,color:"cyan",variant:"soft",title:"Not set",class:"mb-2"})):m("",!0),t(s).cache_type==="lru"?(u(),w("div",Je,[n(C,{modelValue:t(s).cache_size,"onUpdate:modelValue":e[14]||(e[14]=p=>t(s).cache_size=p),type:"number",class:"w-fit",min:"1"},null,8,["modelValue"]),t(s).cache_size!==null?(u(),_(v,{key:0,icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[15]||(e[15]=()=>{t(s)&&(t(s).cache_size=null)})})):m("",!0)])):m("",!0)]),_:1}),n(h,{size:"md",class:"py-3",label:"VAE cpu",description:"Run the VAE on the CPU."},{default:a(()=>[t(s).vae_cpu===null?(u(),_(R,{key:0,color:"cyan",variant:"soft",title:"Not set",class:"mb-2"})):m("",!0),i("div",He,[n(N,{modelValue:t(s).vae_cpu,"onUpdate:modelValue":e[16]||(e[16]=p=>t(s).vae_cpu=p),color:"primary",class:"py-3",label:"VAE on CPU"},null,8,["modelValue"]),t(s).vae_cpu?(u(),_(v,{key:0,icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[17]||(e[17]=()=>{t(s)&&(t(s).vae_cpu=null)})})):m("",!0)])]),_:1}),n(h,{size:"md",class:"py-3",label:"Reserve VRAM",description:"Amount of VRAM in GB to reserve for use."},{default:a(()=>[t(s).reserve_vram===null?(u(),_(R,{key:0,color:"cyan",variant:"soft",title:"Not set",class:"mb-2"})):m("",!0),i("div",Ke,[n(C,{modelValue:t(s).reserve_vram,"onUpdate:modelValue":e[18]||(e[18]=p=>t(s).reserve_vram=p),type:"number",min:"0",step:"0.1",class:"w-fit"},null,8,["modelValue"]),t(s).reserve_vram!==null?(u(),_(v,{key:0,icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[19]||(e[19]=()=>{t(s)&&(t(s).reserve_vram=null)})})):m("",!0)])]),_:1})])):m("",!0),i("div",Qe,[n(v,{class:"mr-2",variant:"solid",color:"green",loading:t(T),onClick:ae},{default:a(()=>e[26]||(e[26]=[r(" Save ")])),_:1,__:[26]},8,["loading"]),n(v,{class:"mr-2",variant:"solid",color:"white",onClick:J},{default:a(()=>e[27]||(e[27]=[r(" Cancel ")])),_:1,__:[27]})])])]}),_:1},8,["modelValue"]),n(ie,{modelValue:t(g),"onUpdate:modelValue":e[21]||(e[21]=l=>S(g)?g.value=l:null),columns:t(M),rows:t(U)===""?t(P):t(X),loading:t(k).$state.loading},{"actions-data":a(({row:l})=>[n(v,{icon:"i-heroicons-pencil-16-solid",variant:"outline",color:"cyan",size:"sm",onClick:()=>{le(l)}},{default:a(()=>e[29]||(e[29]=[r(" Edit ")])),_:2,__:[29]},1032,["onClick"])]),"worker_status-data":a(({row:l})=>[n(V,{variant:"solid",color:Y(l)==="Online"?"green":"red"},{default:a(()=>[r(d(Y(l)),1)]),_:2},1032,["color"])]),"federated-data":a(({row:l})=>[n(V,{variant:"solid",color:l.federated_instance_name!==""?"blue":"green"},{default:a(()=>[r(d(l.federated_instance_name!==""?"Yes":"No"),1)]),_:2},1032,["color"])]),"busy-data":a(({row:l})=>[n(V,{variant:"solid",color:l.empty_task_requests_count===0?"red":"green"},{default:a(()=>[r(d(l.empty_task_requests_count===0?"Yes":"No"),1)]),_:2},1032,["color"])]),"tasks_to_give-data":a(({row:l})=>[l.tasks_to_give.length===0?(u(),w("span",Ze,"All")):(u(),_(re,{key:1,popper:{placement:"bottom"}},{panel:a(()=>[i("div",Xe,[(u(!0),w(ze,null,Be(l.tasks_to_give,p=>(u(),_(V,{key:p,class:"mr-2 mb-2",variant:"solid",color:"cyan"},{default:a(()=>[n(ne,{class:"hover:underline",to:`/workflows/${p}`},{default:a(()=>[r(d(p),1)]),_:2},1032,["to"])]),_:2},1024))),128))])]),default:a(()=>[n(v,{icon:"i-heroicons-list-bullet-16-solid",variant:"outline",color:"gray",size:"sm"},{default:a(()=>[i("span",null,d(l.tasks_to_give.length)+" selected",1)]),_:2},1024)]),_:2},1024))]),"last_seen-data":a(({row:l})=>[r(d(new Date(l.last_seen).toLocaleString()),1)]),"vram_total-data":a(({row:l})=>[r(d(("formatBytes"in o?o.formatBytes:t(x))(l.vram_total)),1)]),"vram_free-data":a(({row:l})=>[r(d(("formatBytes"in o?o.formatBytes:t(x))(l.vram_free)),1)]),"torch_vram_total-data":a(({row:l})=>[r(d(("formatBytes"in o?o.formatBytes:t(x))(l.torch_vram_total)),1)]),"torch_vram_free-data":a(({row:l})=>[r(d(("formatBytes"in o?o.formatBytes:t(x))(l.torch_vram_free)),1)]),"ram_total-data":a(({row:l})=>[r(d(("formatBytes"in o?o.formatBytes:t(x))(l.ram_total)),1)]),"ram_free-data":a(({row:l})=>[r(d(("formatBytes"in o?o.formatBytes:t(x))(l.ram_free)),1)]),"smart_memory-data":a(({row:l})=>[n(V,{variant:"solid",color:l.smart_memory?"green":"red"},{default:a(()=>[r(d(l.smart_memory?"Yes":"No"),1)]),_:2},1032,["color"])]),"cache_type-data":a(({row:l})=>[n(V,{variant:"solid",color:l.cache_type==="none"?"red":"green"},{default:a(()=>[r(d(l.cache_type??t(c).settingsMap.cache_type.value),1)]),_:2},1032,["color"])]),"cache_size-data":a(({row:l})=>[r(d(l.cache_size&&l.cache_type==="lru"?l.cache_size+" nodes":"N/A"),1)]),"vae_cpu-data":a(({row:l})=>[n(V,{variant:"solid",color:l.vae_cpu?"green":"red"},{default:a(()=>[r(d(l.vae_cpu?"Yes":"No"),1)]),_:2},1032,["color"])]),"reserve_vram-data":a(({row:l})=>[r(d(l.reserve_vram??"N/A"),1)]),_:1},8,["modelValue","columns","rows","loading"])])])]),_:1})}}});export{it as default};
