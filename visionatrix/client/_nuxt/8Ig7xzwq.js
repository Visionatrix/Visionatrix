import{_ as ae}from"./B3wTn2IQ.js";import{_ as oe,a as se}from"./D20HAg8t.js";import{a as le,_ as ne}from"./XW-HZBd7.js";import{_ as re}from"./DZjbicC_.js";import{f as ie,u as ue,z as de,y as me,q as ce,V as _e,W as pe,N as f,v as G,g as fe,x as V,M as ve,i as x,w as s,A as ge,o as _,a as u,b as l,p as o,c as M,k as F,d as n,m as ye,P as U,t as i,l as be,O as v,Q as ke,F as we,r as he,j as Ve,G as xe,s as E}from"./DIYZyP7P.js";import{_ as Me}from"./KJYYKDGQ.js";import"./Cty_TBS6.js";const Ue={class:"flex flex-col md:flex-row"},Se={class:"px-5 md:w-4/5"},Ce={key:0},Te={class:"flex flex-col lg:flex-row px-3 py-3.5 border-b border-gray-200 dark:border-gray-700"},Be={class:"flex"},Ae={key:0,class:"flex flex-col md:flex-row items-center"},Re={key:0},De={class:"p-4 flex flex-wrap max-w-64 max-h-60 overflow-y-auto"},Pe=ie({__name:"workers",setup(Ne){ue({title:"Workers - Visionatrix",meta:[{name:"description",content:"Workers - Visionatrix"}]});const p=de(),r=me(),j=ce();_e(()=>{p.startPolling()}),pe(()=>{p.stopPolling()});const S=[{id:"worker_status",label:"Worker status",sortable:!0},{id:"federated",label:"Federated",sortable:!0},{id:"busy",label:"Busy",sortable:!0},{id:"worker_id",label:"Worker ID"},{id:"worker_version",label:"Worker version",sortable:!0},{id:"last_seen",label:"Last seen",sortable:!0},{id:"tasks_to_give",label:"Tasks to give",sortable:!1},{id:"os",label:"OS",sortable:!0},{id:"version",label:"Python Version",sortable:!0},{id:"device_name",label:"Device name"},{id:"device_type",label:"Device type",sortable:!0},{id:"vram_total",label:"VRAM total",sortable:!0},{id:"vram_free",label:"VRAM free",sortable:!0},{id:"torch_vram_total",label:"Torch VRAM total",sortable:!0},{id:"torch_vram_free",label:"Torch VRAM free",sortable:!0},{id:"ram_total",label:"RAM total",sortable:!0},{id:"ram_free",label:"RAM free",sortable:!0}],b=S.map(a=>({key:a.id,label:a.label,sortable:a.sortable||!1,class:""})),O=localStorage.getItem("selectedColumns");let C=null;if(O!==null){const a=JSON.parse(O);C=b.filter(e=>a.includes(e.key)),C.sort(L)}const g=f(C||[...b]);G(g,a=>{localStorage.setItem("selectedColumns",JSON.stringify(Object.values(b).filter(e=>a.includes(e)).map(e=>e.key))),a.sort(L)});function L(a,e){return S.findIndex(d=>d.id===a.key)-S.findIndex(d=>d.id===e.key)}const k=fe(),T=V(()=>[...k.$state.flows_installed,...k.$state.flows_available].map(a=>({label:a.display_name,value:a.name}))),m=f([]);ve(()=>{if(k.flows.length===0){k.fetchFlows().then(()=>{m.value=[...T.value]});return}m.value=[...T.value]});const q=V(()=>m.value.length===0?"All":m.value.length),B=f(!1);function H(){B.value=!0,Promise.all(c.value.filter(a=>a.federated_instance_name==="").map(a=>p.setTasksToGive(a.worker_id,m.value.map(e=>e.value)))).then(()=>{E().add({title:"Tasks to give updated",description:"Tasks to give updated successfully"}),c.value=[]}).catch(()=>{E().add({title:"Failed to update tasks to give",description:"Try again"})}).finally(()=>{B.value=!1,p.loadWorkers()})}const y=f(""),A=V(()=>p.$state.workers),J=V(()=>A.value.filter(a=>Object.values(a).some(e=>String(e).toLowerCase().includes(y.value.toLowerCase()))));function $(a){const e=new Date(a.last_seen.includes("Z")?a.last_seen:a.last_seen+"Z");return new Date().getTime()-e.getTime()<=60*5*1e3?"Online":"Offline"}const c=f([]);G(A,a=>{if(c.value.length>0){const e=c.value.map(d=>d.worker_id);c.value=a.filter(d=>e.includes(d.worker_id))}});const K=["smart_memory","cache_type","cache_size","vae_cpu"],R=f(!1);function Q(){R.value=!0,r.saveChanges(K).finally(()=>{R.value=!1})}return(a,e)=>{const d=ae,D=oe,I=le,N=se,W=re,P=ne,w=ye,Y=be,h=Ve,Z=xe,X=ke,ee=Me,te=ge;return _(),x(te,{class:"lg:h-dvh"},{default:s(()=>[u("div",Ue,[l(d,{links:o(r).links,class:"md:w-1/5"},null,8,["links"]),u("div",Se,[e[13]||(e[13]=u("h2",{class:"mb-3 text-xl"},"Workers",-1)),o(j).isAdmin?(_(),M("div",Ce,[l(D,{class:"mb-3",label:"Default Workers settings"}),l(N,{size:"md",class:"py-3",label:"Smart memory",description:"When disabled forces ComfyUI to aggressively offload to regular RAM instead of keeping models in VRAM when it can."},{default:s(()=>[l(I,{modelValue:o(r).settingsMap.smart_memory.value,"onUpdate:modelValue":e[0]||(e[0]=t=>o(r).settingsMap.smart_memory.value=t),color:"primary",label:"Enable smart memory"},null,8,["modelValue"])]),_:1}),l(N,{size:"md",class:"py-3",label:"Cache type"},{description:s(()=>e[10]||(e[10]=[u("p",null,[n(" Classic - Use the old style (aggressive) caching. "),u("br"),n(" LRU - Use LRU caching with a maximum of N node results cached. May use more RAM/VRAM. "),u("br"),n(" None - Reduced RAM/VRAM usage at the expense of executing every node for each run. "),u("br")],-1)])),default:s(()=>[l(W,{modelValue:o(r).settingsMap.cache_type.value,"onUpdate:modelValue":e[1]||(e[1]=t=>o(r).settingsMap.cache_type.value=t),class:"w-fit",placeholder:"Select cache type","value-attribute":"value",options:o(r).settingsMap.cache_type.options},null,8,["modelValue","options"]),o(r).settingsMap.cache_type.value==="lru"?(_(),x(P,{key:0,modelValue:o(r).settingsMap.cache_size.value,"onUpdate:modelValue":e[2]||(e[2]=t=>o(r).settingsMap.cache_size.value=t),type:"number",class:"w-fit mt-3",min:"1",onChange:e[3]||(e[3]=()=>{o(r).settingsMap.cache_size.value=o(r).settingsMap.cache_size.value.toString()})},null,8,["modelValue"])):F("",!0)]),_:1}),l(N,{size:"md",class:"py-3",label:"VAE cpu",description:"Run the VAE on the CPU."},{default:s(()=>[l(I,{modelValue:o(r).settingsMap.vae_cpu.value,"onUpdate:modelValue":e[4]||(e[4]=t=>o(r).settingsMap.vae_cpu.value=t),color:"primary",label:"VAE on CPU"},null,8,["modelValue"])]),_:1}),l(w,{class:"mt-3",icon:"i-heroicons-check-16-solid",loading:o(R),onClick:Q},{default:s(()=>e[11]||(e[11]=[n(" Save ")])),_:1},8,["loading"])])):F("",!0),l(D,{class:"my-3"}),u("div",Te,[u("div",Be,[l(W,{modelValue:o(g),"onUpdate:modelValue":e[5]||(e[5]=t=>U(g)?g.value=t:null),class:"mr-3",options:o(b),multiple:""},null,8,["modelValue","options"]),l(P,{modelValue:o(y),"onUpdate:modelValue":e[6]||(e[6]=t=>U(y)?y.value=t:null),placeholder:"Filter workers..."},null,8,["modelValue"])]),o(c).length>=1?(_(),M("div",Ae,[l(W,{modelValue:o(m),"onUpdate:modelValue":e[7]||(e[7]=t=>U(m)?m.value=t:null),searchable:"",class:"mr-3 my-3 lg:mx-3 lg:my-0 w-full max-w-64 min-w-64",options:o(T),multiple:""},{label:s(()=>[u("span",null,"Tasks to give ("+i(o(q))+")",1)]),_:1},8,["modelValue","options"]),l(Y,{text:"Flows available for worker to get tasks"},{default:s(()=>[l(w,{icon:"i-heroicons-check-16-solid",variant:"outline",color:"cyan",size:"sm",loading:o(B),onClick:H},{default:s(()=>e[12]||(e[12]=[n(" Update tasks to give ")])),_:1},8,["loading"])]),_:1}),l(w,{icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[8]||(e[8]=()=>{m.value=[]})})])):F("",!0)]),l(ee,{modelValue:o(c),"onUpdate:modelValue":e[9]||(e[9]=t=>U(c)?c.value=t:null),columns:o(g),rows:o(y)===""?o(A):o(J),loading:o(p).$state.loading},{"worker_status-data":s(({row:t})=>[l(h,{variant:"solid",color:$(t)==="Online"?"green":"red"},{default:s(()=>[n(i($(t)),1)]),_:2},1032,["color"])]),"federated-data":s(({row:t})=>[l(h,{variant:"solid",color:t.federated_instance_name!==""?"blue":"green"},{default:s(()=>[n(i(t.federated_instance_name!==""?"Yes":"No"),1)]),_:2},1032,["color"])]),"busy-data":s(({row:t})=>[l(h,{variant:"solid",color:t.empty_task_requests_count===0?"red":"green"},{default:s(()=>[n(i(t.empty_task_requests_count===0?"Yes":"No"),1)]),_:2},1032,["color"])]),"tasks_to_give-data":s(({row:t})=>[t.tasks_to_give.length===0?(_(),M("span",Re,"All")):(_(),x(X,{key:1,popper:{placement:"bottom"}},{panel:s(()=>[u("div",De,[(_(!0),M(we,null,he(t.tasks_to_give,z=>(_(),x(h,{key:z,class:"mr-2 mb-2",variant:"solid",color:"cyan"},{default:s(()=>[l(Z,{class:"hover:underline",to:`/workflows/${z}`},{default:s(()=>[n(i(z),1)]),_:2},1032,["to"])]),_:2},1024))),128))])]),default:s(()=>[l(w,{icon:"i-heroicons-list-bullet-16-solid",variant:"outline",color:"gray",size:"sm"},{default:s(()=>[u("span",null,i(t.tasks_to_give.length)+" selected",1)]),_:2},1024)]),_:2},1024))]),"last_seen-data":s(({row:t})=>[n(i(new Date(t.last_seen).toLocaleString()),1)]),"vram_total-data":s(({row:t})=>[n(i(("formatBytes"in a?a.formatBytes:o(v))(t.vram_total)),1)]),"vram_free-data":s(({row:t})=>[n(i(("formatBytes"in a?a.formatBytes:o(v))(t.vram_free)),1)]),"torch_vram_total-data":s(({row:t})=>[n(i(("formatBytes"in a?a.formatBytes:o(v))(t.torch_vram_total)),1)]),"torch_vram_free-data":s(({row:t})=>[n(i(("formatBytes"in a?a.formatBytes:o(v))(t.torch_vram_free)),1)]),"ram_total-data":s(({row:t})=>[n(i(("formatBytes"in a?a.formatBytes:o(v))(t.ram_total)),1)]),"ram_free-data":s(({row:t})=>[n(i(("formatBytes"in a?a.formatBytes:o(v))(t.ram_free)),1)]),_:1},8,["modelValue","columns","rows","loading"])])])]),_:1})}}});export{Pe as default};
