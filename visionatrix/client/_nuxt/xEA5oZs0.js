import{_ as te}from"./QtR54gxE.js";import{_ as ae,a as oe}from"./BGxIsmUO.js";import{a as se,_ as le}from"./DOwWiVp_.js";import{_ as ne}from"./R4WQrWeY.js";import{f as re,u as ie,z as ue,y as de,V as me,W as ce,N as f,v as I,g as _e,x,M as pe,i as V,w as s,A as fe,o as _,a as u,b as l,p as o,k as G,d as n,m as ve,c as W,P as M,t as r,l as ge,O as v,Q as ye,F as be,r as ke,j as we,G as he,s as P}from"./DWidcIQT.js";import{_ as xe}from"./CDjI1TIO.js";import"./CeW-u91L.js";const Ve={class:"flex flex-col md:flex-row"},Me={class:"px-5 md:w-4/5"},Se={class:"flex flex-col lg:flex-row px-3 py-3.5 border-b border-gray-200 dark:border-gray-700"},Ue={class:"flex"},Ce={key:0,class:"flex flex-col md:flex-row items-center"},Te={key:0},Be={class:"p-4 flex flex-wrap max-w-64 max-h-60 overflow-y-auto"},Le=re({__name:"workers",setup(Re){ie({title:"Workers - Visionatrix",meta:[{name:"description",content:"Workers - Visionatrix"}]});const p=ue(),i=de();me(()=>{p.startPolling()}),ce(()=>{p.stopPolling()});const S=[{id:"worker_status",label:"Worker status",sortable:!0},{id:"federated",label:"Federated",sortable:!0},{id:"busy",label:"Busy",sortable:!0},{id:"worker_id",label:"Worker ID"},{id:"worker_version",label:"Worker version",sortable:!0},{id:"last_seen",label:"Last seen",sortable:!0},{id:"tasks_to_give",label:"Tasks to give",sortable:!1},{id:"os",label:"OS",sortable:!0},{id:"version",label:"Python Version",sortable:!0},{id:"device_name",label:"Device name"},{id:"device_type",label:"Device type",sortable:!0},{id:"vram_total",label:"VRAM total",sortable:!0},{id:"vram_free",label:"VRAM free",sortable:!0},{id:"torch_vram_total",label:"Torch VRAM total",sortable:!0},{id:"torch_vram_free",label:"Torch VRAM free",sortable:!0},{id:"ram_total",label:"RAM total",sortable:!0},{id:"ram_free",label:"RAM free",sortable:!0}],b=S.map(t=>({key:t.id,label:t.label,sortable:t.sortable||!1,class:""})),F=localStorage.getItem("selectedColumns");let U=null;if(F!==null){const t=JSON.parse(F);U=b.filter(e=>t.includes(e.key)),U.sort(O)}const g=f(U||[...b]);I(g,t=>{localStorage.setItem("selectedColumns",JSON.stringify(Object.values(b).filter(e=>t.includes(e)).map(e=>e.key))),t.sort(O)});function O(t,e){return S.findIndex(d=>d.id===t.key)-S.findIndex(d=>d.id===e.key)}const k=_e(),C=x(()=>[...k.$state.flows_installed,...k.$state.flows_available].map(t=>({label:t.display_name,value:t.name}))),m=f([]);pe(()=>{if(k.flows.length===0){k.fetchFlows().then(()=>{m.value=[...C.value]});return}m.value=[...C.value]});const j=x(()=>m.value.length===0?"All":m.value.length),T=f(!1);function q(){T.value=!0,Promise.all(c.value.filter(t=>t.federated_instance_name==="").map(t=>p.setTasksToGive(t.worker_id,m.value.map(e=>e.value)))).then(()=>{P().add({title:"Tasks to give updated",description:"Tasks to give updated successfully"}),c.value=[]}).catch(()=>{P().add({title:"Failed to update tasks to give",description:"Try again"})}).finally(()=>{T.value=!1,p.loadWorkers()})}const y=f(""),B=x(()=>p.$state.workers),E=x(()=>B.value.filter(t=>Object.values(t).some(e=>String(e).toLowerCase().includes(y.value.toLowerCase()))));function z(t){const e=new Date(t.last_seen.includes("Z")?t.last_seen:t.last_seen+"Z");return new Date().getTime()-e.getTime()<=60*5*1e3?"Online":"Offline"}const c=f([]);I(B,t=>{if(c.value.length>0){const e=c.value.map(d=>d.worker_id);c.value=t.filter(d=>e.includes(d.worker_id))}});const H=["smart_memory","cache_type","cache_size"],R=f(!1);function J(){R.value=!0,i.saveChanges(H).finally(()=>{R.value=!1})}return(t,e)=>{const d=te,A=ae,K=se,L=oe,D=ne,$=le,w=ve,Q=ge,h=we,Y=he,Z=ye,X=xe,ee=fe;return _(),V(ee,{class:"lg:h-dvh"},{default:s(()=>[u("div",Ve,[l(d,{links:o(i).links,class:"md:w-1/5"},null,8,["links"]),u("div",Me,[e[12]||(e[12]=u("h2",{class:"mb-3 text-xl"},"Workers",-1)),l(A,{class:"mb-3",label:"Default Workers settings"}),l(L,{size:"md",class:"py-3",label:"Smart memory",description:"When disabled forces ComfyUI to aggressively offload to regular ram instead of keeping models in vram when it can."},{default:s(()=>[l(K,{modelValue:o(i).settingsMap.smart_memory.value,"onUpdate:modelValue":e[0]||(e[0]=a=>o(i).settingsMap.smart_memory.value=a),color:"primary",label:"Enable smart memory"},null,8,["modelValue"])]),_:1}),l(L,{size:"md",class:"py-3",label:"Cache type"},{description:s(()=>e[9]||(e[9]=[u("p",null,[n(" Classic - Use the old style (aggressive) caching. "),u("br"),n(" LRU - Use LRU caching with a maximum of N node results cached. May use more RAM/VRAM. "),u("br"),n(" None - Reduced RAM/VRAM usage at the expense of executing every node for each run. "),u("br")],-1)])),default:s(()=>[l(D,{modelValue:o(i).settingsMap.cache_type.value,"onUpdate:modelValue":e[1]||(e[1]=a=>o(i).settingsMap.cache_type.value=a),class:"w-fit",placeholder:"Select cache type","value-attribute":"value",options:o(i).settingsMap.cache_type.options},null,8,["modelValue","options"]),o(i).settingsMap.cache_type.value==="lru"?(_(),V($,{key:0,modelValue:o(i).settingsMap.cache_size.value,"onUpdate:modelValue":e[2]||(e[2]=a=>o(i).settingsMap.cache_size.value=a),type:"number",class:"w-fit mt-3",min:"1",onChange:e[3]||(e[3]=()=>{o(i).settingsMap.cache_size.value=o(i).settingsMap.cache_size.value.toString()})},null,8,["modelValue"])):G("",!0)]),_:1}),l(w,{class:"mt-3",icon:"i-heroicons-check-16-solid",loading:o(R),onClick:J},{default:s(()=>e[10]||(e[10]=[n(" Save ")])),_:1},8,["loading"]),l(A,{class:"my-3"}),u("div",Se,[u("div",Ue,[l(D,{modelValue:o(g),"onUpdate:modelValue":e[4]||(e[4]=a=>M(g)?g.value=a:null),class:"mr-3",options:o(b),multiple:""},null,8,["modelValue","options"]),l($,{modelValue:o(y),"onUpdate:modelValue":e[5]||(e[5]=a=>M(y)?y.value=a:null),placeholder:"Filter workers..."},null,8,["modelValue"])]),o(c).length>=1?(_(),W("div",Ce,[l(D,{modelValue:o(m),"onUpdate:modelValue":e[6]||(e[6]=a=>M(m)?m.value=a:null),searchable:"",class:"mr-3 my-3 lg:mx-3 lg:my-0 w-full max-w-64 min-w-64",options:o(C),multiple:""},{label:s(()=>[u("span",null,"Tasks to give ("+r(o(j))+")",1)]),_:1},8,["modelValue","options"]),l(Q,{text:"Flows available for worker to get tasks"},{default:s(()=>[l(w,{icon:"i-heroicons-check-16-solid",variant:"outline",color:"cyan",size:"sm",loading:o(T),onClick:q},{default:s(()=>e[11]||(e[11]=[n(" Update tasks to give ")])),_:1},8,["loading"])]),_:1}),l(w,{icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[7]||(e[7]=()=>{m.value=[]})})])):G("",!0)]),l(X,{modelValue:o(c),"onUpdate:modelValue":e[8]||(e[8]=a=>M(c)?c.value=a:null),columns:o(g),rows:o(y)===""?o(B):o(E),loading:o(p).$state.loading},{"worker_status-data":s(({row:a})=>[l(h,{variant:"solid",color:z(a)==="Online"?"green":"red"},{default:s(()=>[n(r(z(a)),1)]),_:2},1032,["color"])]),"federated-data":s(({row:a})=>[l(h,{variant:"solid",color:a.federated_instance_name!==""?"blue":"green"},{default:s(()=>[n(r(a.federated_instance_name!==""?"Yes":"No"),1)]),_:2},1032,["color"])]),"busy-data":s(({row:a})=>[l(h,{variant:"solid",color:a.empty_task_requests_count===0?"red":"green"},{default:s(()=>[n(r(a.empty_task_requests_count===0?"Yes":"No"),1)]),_:2},1032,["color"])]),"tasks_to_give-data":s(({row:a})=>[a.tasks_to_give.length===0?(_(),W("span",Te,"All")):(_(),V(Z,{key:1,popper:{placement:"bottom"}},{panel:s(()=>[u("div",Be,[(_(!0),W(be,null,ke(a.tasks_to_give,N=>(_(),V(h,{key:N,class:"mr-2 mb-2",variant:"solid",color:"cyan"},{default:s(()=>[l(Y,{class:"hover:underline",to:`/workflows/${N}`},{default:s(()=>[n(r(N),1)]),_:2},1032,["to"])]),_:2},1024))),128))])]),default:s(()=>[l(w,{icon:"i-heroicons-list-bullet-16-solid",variant:"outline",color:"gray",size:"sm"},{default:s(()=>[u("span",null,r(a.tasks_to_give.length)+" selected",1)]),_:2},1024)]),_:2},1024))]),"last_seen-data":s(({row:a})=>[n(r(new Date(a.last_seen).toLocaleString()),1)]),"vram_total-data":s(({row:a})=>[n(r(("formatBytes"in t?t.formatBytes:o(v))(a.vram_total)),1)]),"vram_free-data":s(({row:a})=>[n(r(("formatBytes"in t?t.formatBytes:o(v))(a.vram_free)),1)]),"torch_vram_total-data":s(({row:a})=>[n(r(("formatBytes"in t?t.formatBytes:o(v))(a.torch_vram_total)),1)]),"torch_vram_free-data":s(({row:a})=>[n(r(("formatBytes"in t?t.formatBytes:o(v))(a.torch_vram_free)),1)]),"ram_total-data":s(({row:a})=>[n(r(("formatBytes"in t?t.formatBytes:o(v))(a.ram_total)),1)]),"ram_free-data":s(({row:a})=>[n(r(("formatBytes"in t?t.formatBytes:o(v))(a.ram_free)),1)]),_:1},8,["modelValue","columns","rows","loading"])])])]),_:1})}}});export{Le as default};
