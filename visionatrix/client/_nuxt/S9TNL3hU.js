import{_ as te}from"./DVBiUmEM.js";import{_ as ae,a as oe}from"./DX7AAPOp.js";import{a as se,_ as le}from"./wKaNWGWJ.js";import{_ as ne}from"./RKebFPQ7.js";import{f as re,u as ie,z as ue,y as de,V as me,W as ce,N as f,v as P,g as _e,x as h,M as pe,i as x,w as s,A as fe,o as _,a as u,b as l,p as o,k as G,d as n,m as ve,c as z,P as M,t as i,l as ge,O as v,Q as ye,F as be,r as ke,j as we,G as Ve,s as E}from"./H93ddWTI.js";import{_ as he}from"./CAHuZHMa.js";import"./peITnDi6.js";const xe={class:"flex flex-col md:flex-row"},Me={class:"px-5 md:w-4/5"},Ue={class:"flex flex-col lg:flex-row px-3 py-3.5 border-b border-gray-200 dark:border-gray-700"},Se={class:"flex"},Ce={key:0,class:"flex flex-col md:flex-row items-center"},Te={key:0},Be={class:"p-4 flex flex-wrap max-w-64 max-h-60 overflow-y-auto"},Le=re({__name:"workers",setup(Ae){ie({title:"Workers - Visionatrix",meta:[{name:"description",content:"Workers - Visionatrix"}]});const p=ue(),r=de();me(()=>{p.startPolling()}),ce(()=>{p.stopPolling()});const U=[{id:"worker_status",label:"Worker status",sortable:!0},{id:"federated",label:"Federated",sortable:!0},{id:"busy",label:"Busy",sortable:!0},{id:"worker_id",label:"Worker ID"},{id:"worker_version",label:"Worker version",sortable:!0},{id:"last_seen",label:"Last seen",sortable:!0},{id:"tasks_to_give",label:"Tasks to give",sortable:!1},{id:"os",label:"OS",sortable:!0},{id:"version",label:"Python Version",sortable:!0},{id:"device_name",label:"Device name"},{id:"device_type",label:"Device type",sortable:!0},{id:"vram_total",label:"VRAM total",sortable:!0},{id:"vram_free",label:"VRAM free",sortable:!0},{id:"torch_vram_total",label:"Torch VRAM total",sortable:!0},{id:"torch_vram_free",label:"Torch VRAM free",sortable:!0},{id:"ram_total",label:"RAM total",sortable:!0},{id:"ram_free",label:"RAM free",sortable:!0}],b=U.map(a=>({key:a.id,label:a.label,sortable:a.sortable||!1,class:""})),F=localStorage.getItem("selectedColumns");let S=null;if(F!==null){const a=JSON.parse(F);S=b.filter(e=>a.includes(e.key)),S.sort(O)}const g=f(S||[...b]);P(g,a=>{localStorage.setItem("selectedColumns",JSON.stringify(Object.values(b).filter(e=>a.includes(e)).map(e=>e.key))),a.sort(O)});function O(a,e){return U.findIndex(d=>d.id===a.key)-U.findIndex(d=>d.id===e.key)}const k=_e(),C=h(()=>[...k.$state.flows_installed,...k.$state.flows_available].map(a=>({label:a.display_name,value:a.name}))),m=f([]);pe(()=>{if(k.flows.length===0){k.fetchFlows().then(()=>{m.value=[...C.value]});return}m.value=[...C.value]});const j=h(()=>m.value.length===0?"All":m.value.length),T=f(!1);function q(){T.value=!0,Promise.all(c.value.filter(a=>a.federated_instance_name==="").map(a=>p.setTasksToGive(a.worker_id,m.value.map(e=>e.value)))).then(()=>{E().add({title:"Tasks to give updated",description:"Tasks to give updated successfully"}),c.value=[]}).catch(()=>{E().add({title:"Failed to update tasks to give",description:"Try again"})}).finally(()=>{T.value=!1,p.loadWorkers()})}const y=f(""),B=h(()=>p.$state.workers),H=h(()=>B.value.filter(a=>Object.values(a).some(e=>String(e).toLowerCase().includes(y.value.toLowerCase()))));function L(a){const e=new Date(a.last_seen.includes("Z")?a.last_seen:a.last_seen+"Z");return new Date().getTime()-e.getTime()<=60*5*1e3?"Online":"Offline"}const c=f([]);P(B,a=>{if(c.value.length>0){const e=c.value.map(d=>d.worker_id);c.value=a.filter(d=>e.includes(d.worker_id))}});const J=["smart_memory","cache_type","cache_size","vae_cpu"],A=f(!1);function K(){A.value=!0,r.saveChanges(J).finally(()=>{A.value=!1})}return(a,e)=>{const d=te,R=ae,$=se,D=oe,N=ne,I=le,w=ve,Q=ge,V=we,Y=Ve,Z=ye,X=he,ee=fe;return _(),x(ee,{class:"lg:h-dvh"},{default:s(()=>[u("div",xe,[l(d,{links:o(r).links,class:"md:w-1/5"},null,8,["links"]),u("div",Me,[e[13]||(e[13]=u("h2",{class:"mb-3 text-xl"},"Workers",-1)),l(R,{class:"mb-3",label:"Default Workers settings"}),l(D,{size:"md",class:"py-3",label:"Smart memory",description:"When disabled forces ComfyUI to aggressively offload to regular RAM instead of keeping models in VRAM when it can."},{default:s(()=>[l($,{modelValue:o(r).settingsMap.smart_memory.value,"onUpdate:modelValue":e[0]||(e[0]=t=>o(r).settingsMap.smart_memory.value=t),color:"primary",label:"Enable smart memory"},null,8,["modelValue"])]),_:1}),l(D,{size:"md",class:"py-3",label:"Cache type"},{description:s(()=>e[10]||(e[10]=[u("p",null,[n(" Classic - Use the old style (aggressive) caching. "),u("br"),n(" LRU - Use LRU caching with a maximum of N node results cached. May use more RAM/VRAM. "),u("br"),n(" None - Reduced RAM/VRAM usage at the expense of executing every node for each run. "),u("br")],-1)])),default:s(()=>[l(N,{modelValue:o(r).settingsMap.cache_type.value,"onUpdate:modelValue":e[1]||(e[1]=t=>o(r).settingsMap.cache_type.value=t),class:"w-fit",placeholder:"Select cache type","value-attribute":"value",options:o(r).settingsMap.cache_type.options},null,8,["modelValue","options"]),o(r).settingsMap.cache_type.value==="lru"?(_(),x(I,{key:0,modelValue:o(r).settingsMap.cache_size.value,"onUpdate:modelValue":e[2]||(e[2]=t=>o(r).settingsMap.cache_size.value=t),type:"number",class:"w-fit mt-3",min:"1",onChange:e[3]||(e[3]=()=>{o(r).settingsMap.cache_size.value=o(r).settingsMap.cache_size.value.toString()})},null,8,["modelValue"])):G("",!0)]),_:1}),l(D,{size:"md",class:"py-3",label:"VAE cpu",description:"Run the VAE on the CPU."},{default:s(()=>[l($,{modelValue:o(r).settingsMap.vae_cpu.value,"onUpdate:modelValue":e[4]||(e[4]=t=>o(r).settingsMap.vae_cpu.value=t),color:"primary",label:"VAE on CPU"},null,8,["modelValue"])]),_:1}),l(w,{class:"mt-3",icon:"i-heroicons-check-16-solid",loading:o(A),onClick:K},{default:s(()=>e[11]||(e[11]=[n(" Save ")])),_:1},8,["loading"]),l(R,{class:"my-3"}),u("div",Ue,[u("div",Se,[l(N,{modelValue:o(g),"onUpdate:modelValue":e[5]||(e[5]=t=>M(g)?g.value=t:null),class:"mr-3",options:o(b),multiple:""},null,8,["modelValue","options"]),l(I,{modelValue:o(y),"onUpdate:modelValue":e[6]||(e[6]=t=>M(y)?y.value=t:null),placeholder:"Filter workers..."},null,8,["modelValue"])]),o(c).length>=1?(_(),z("div",Ce,[l(N,{modelValue:o(m),"onUpdate:modelValue":e[7]||(e[7]=t=>M(m)?m.value=t:null),searchable:"",class:"mr-3 my-3 lg:mx-3 lg:my-0 w-full max-w-64 min-w-64",options:o(C),multiple:""},{label:s(()=>[u("span",null,"Tasks to give ("+i(o(j))+")",1)]),_:1},8,["modelValue","options"]),l(Q,{text:"Flows available for worker to get tasks"},{default:s(()=>[l(w,{icon:"i-heroicons-check-16-solid",variant:"outline",color:"cyan",size:"sm",loading:o(T),onClick:q},{default:s(()=>e[12]||(e[12]=[n(" Update tasks to give ")])),_:1},8,["loading"])]),_:1}),l(w,{icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[8]||(e[8]=()=>{m.value=[]})})])):G("",!0)]),l(X,{modelValue:o(c),"onUpdate:modelValue":e[9]||(e[9]=t=>M(c)?c.value=t:null),columns:o(g),rows:o(y)===""?o(B):o(H),loading:o(p).$state.loading},{"worker_status-data":s(({row:t})=>[l(V,{variant:"solid",color:L(t)==="Online"?"green":"red"},{default:s(()=>[n(i(L(t)),1)]),_:2},1032,["color"])]),"federated-data":s(({row:t})=>[l(V,{variant:"solid",color:t.federated_instance_name!==""?"blue":"green"},{default:s(()=>[n(i(t.federated_instance_name!==""?"Yes":"No"),1)]),_:2},1032,["color"])]),"busy-data":s(({row:t})=>[l(V,{variant:"solid",color:t.empty_task_requests_count===0?"red":"green"},{default:s(()=>[n(i(t.empty_task_requests_count===0?"Yes":"No"),1)]),_:2},1032,["color"])]),"tasks_to_give-data":s(({row:t})=>[t.tasks_to_give.length===0?(_(),z("span",Te,"All")):(_(),x(Z,{key:1,popper:{placement:"bottom"}},{panel:s(()=>[u("div",Be,[(_(!0),z(be,null,ke(t.tasks_to_give,W=>(_(),x(V,{key:W,class:"mr-2 mb-2",variant:"solid",color:"cyan"},{default:s(()=>[l(Y,{class:"hover:underline",to:`/workflows/${W}`},{default:s(()=>[n(i(W),1)]),_:2},1032,["to"])]),_:2},1024))),128))])]),default:s(()=>[l(w,{icon:"i-heroicons-list-bullet-16-solid",variant:"outline",color:"gray",size:"sm"},{default:s(()=>[u("span",null,i(t.tasks_to_give.length)+" selected",1)]),_:2},1024)]),_:2},1024))]),"last_seen-data":s(({row:t})=>[n(i(new Date(t.last_seen).toLocaleString()),1)]),"vram_total-data":s(({row:t})=>[n(i(("formatBytes"in a?a.formatBytes:o(v))(t.vram_total)),1)]),"vram_free-data":s(({row:t})=>[n(i(("formatBytes"in a?a.formatBytes:o(v))(t.vram_free)),1)]),"torch_vram_total-data":s(({row:t})=>[n(i(("formatBytes"in a?a.formatBytes:o(v))(t.torch_vram_total)),1)]),"torch_vram_free-data":s(({row:t})=>[n(i(("formatBytes"in a?a.formatBytes:o(v))(t.torch_vram_free)),1)]),"ram_total-data":s(({row:t})=>[n(i(("formatBytes"in a?a.formatBytes:o(v))(t.ram_total)),1)]),"ram_free-data":s(({row:t})=>[n(i(("formatBytes"in a?a.formatBytes:o(v))(t.ram_free)),1)]),_:1},8,["modelValue","columns","rows","loading"])])])]),_:1})}}});export{Le as default};
