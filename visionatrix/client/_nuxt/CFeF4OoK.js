import{_ as ce}from"./B76PA_YT.js";import{a as de,_ as me}from"./Ur8lQ-Rf.js";import{a as _e,_ as pe}from"./ajEgCHXD.js";import{_ as fe,a as ve}from"./CAkYmrnE.js";import{f as ye,u as ge,z as ke,y as be,q as he,S as Ve,T as we,B as k,v as H,g as xe,x as N,C as Ue,i as _,w as a,A as Ce,o as u,a as i,b as n,p as t,c as w,k as m,d as r,m as Me,P as A,t as c,l as Ae,j as Se,D as x,Q as Re,F as ze,r as Te,J as Be,s as E}from"./DU29XxQ2.js";import{a as We,_ as Ne}from"./tsVGj29m.js";import"./BOToq9ty.js";const Ee={class:"flex flex-col md:flex-row"},De={class:"px-5 md:w-4/5"},Fe={key:0},Le={class:"flex w-full items-center my-2"},Oe={class:"flex flex-col lg:flex-row px-3 py-3.5 border-b border-gray-200 dark:border-gray-700"},Pe={class:"flex"},Ie={key:0,class:"flex flex-col md:flex-row items-center"},$e={class:"p-4 overflow-y-auto relative"},Ge={class:"text-sm text-slate-500"},je={key:0},Ye={class:"flex items-center w-full"},qe={class:"flex w-full items-center my-2"},Je={key:2,class:"flex w-full items-center my-2"},He={class:"flex items-center w-full"},Ke={class:"flex justify-end my-4"},Qe={key:0},Ze={class:"p-4 flex flex-wrap max-w-64 max-h-60 overflow-y-auto"},rt=ye({__name:"workers",setup(Xe){ge({title:"Workers - Visionatrix",meta:[{name:"description",content:"Workers - Visionatrix"}]});const b=ke(),d=be(),K=he();Ve(()=>{b.startPolling()}),we(()=>{b.stopPolling()});const D=[{id:"actions",label:"Actions",sortable:!1},{id:"worker_status",label:"Worker status",sortable:!0},{id:"federated",label:"Federated",sortable:!0},{id:"busy",label:"Busy",sortable:!0},{id:"worker_id",label:"Worker ID"},{id:"worker_version",label:"Worker version",sortable:!0},{id:"last_seen",label:"Last seen",sortable:!0},{id:"tasks_to_give",label:"Tasks to give",sortable:!1},{id:"os",label:"OS",sortable:!0},{id:"version",label:"Python Version",sortable:!0},{id:"device_name",label:"Device name"},{id:"device_type",label:"Device type",sortable:!0},{id:"vram_total",label:"VRAM total",sortable:!0},{id:"vram_free",label:"VRAM free",sortable:!0},{id:"torch_vram_total",label:"Torch VRAM total",sortable:!0},{id:"torch_vram_free",label:"Torch VRAM free",sortable:!0},{id:"ram_total",label:"RAM total",sortable:!0},{id:"ram_free",label:"RAM free",sortable:!0},{id:"smart_memory",label:"Smart memory",sortable:!0},{id:"cache_type",label:"Cache type",sortable:!0},{id:"cache_size",label:"Cache size",sortable:!0},{id:"vae_cpu",label:"VAE CPU",sortable:!0}],S=D.map(o=>({key:o.id,label:o.label,sortable:o.sortable||!1,class:""})),G=localStorage.getItem("selectedColumns");let F=null;if(G!==null){const o=JSON.parse(G);F=S.filter(e=>o.includes(e.key)),F.sort(j)}const U=k(F||[...S]);H(U,o=>{localStorage.setItem("selectedColumns",JSON.stringify(Object.values(S).filter(e=>o.includes(e)).map(e=>e.key))),o.sort(j)});function j(o,e){return D.findIndex(v=>v.id===o.key)-D.findIndex(v=>v.id===e.key)}const R=xe(),L=N(()=>[...R.$state.flows_installed,...R.$state.flows_available].map(o=>({label:o.display_name,value:o.name}))),y=k([]);Ue(()=>{if(R.flows.length===0){R.fetchFlows().then(()=>{y.value=[...L.value]});return}y.value=[...L.value]});const Q=N(()=>y.value.length===0?"All":y.value.length),z=k(!1);function Z(){z.value=!0,Promise.all(g.value.filter(o=>o.federated_instance_name==="").map(o=>b.setTasksToGive(o.worker_id,y.value.map(e=>e.value)))).then(()=>{E().add({title:"Tasks to give updated",description:"Tasks to give updated successfully"}),g.value=[]}).catch(()=>{E().add({title:"Failed to update tasks to give",description:"Try again"})}).finally(()=>{z.value=!1,b.loadWorkers()})}const C=k(""),O=N(()=>b.$state.workers),X=N(()=>O.value.filter(o=>Object.values(o).some(e=>String(e).toLowerCase().includes(C.value.toLowerCase()))));function Y(o){const e=new Date(o.last_seen.includes("Z")?o.last_seen:o.last_seen+"Z");return new Date().getTime()-e.getTime()<=60*5*1e3?"Online":"Offline"}const g=k([]);H(O,o=>{if(g.value.length>0){const e=g.value.map(v=>v.worker_id);g.value=o.filter(v=>e.includes(v.worker_id))}});const ee=["smart_memory","cache_type","cache_size","vae_cpu"],q=k(!1);function te(){q.value=!0,d.saveChanges(ee).finally(()=>{q.value=!1})}const M=k(!1),s=k(null),le=o=>{s.value=o,M.value=!0},J=()=>{M.value=!1,s.value=null},P=k(!1),oe=()=>{s.value&&(P.value=!0,b.updateWorkerOptions(s.value.worker_id,{smart_memory:s.value.smart_memory??null,cache_type:s.value.cache_type??null,cache_size:s.value.cache_size??null,vae_cpu:s.value.vae_cpu??null}).then(()=>{E().add({title:"Worker options updated",description:"Worker options updated successfully"}),b.loadWorkers()}).catch(()=>{E().add({title:"Failed to update worker options",description:"Try again"})}).finally(()=>{P.value=!1,J()}))};return(o,e)=>{const v=ce,I=de,T=_e,V=me,B=fe,$=pe,p=Me,ae=Ae,W=ve,se=We,h=Se,ne=Be,re=Re,ie=Ne,ue=Ce;return u(),_(ue,{class:"lg:h-dvh"},{default:a(()=>[i("div",Ee,[n(v,{links:t(d).links,class:"md:w-1/5"},null,8,["links"]),i("div",De,[e[27]||(e[27]=i("h2",{class:"mb-3 text-xl"},"Workers",-1)),t(K).isAdmin?(u(),w("div",Fe,[n(I,{class:"mb-3",label:"Default Workers settings"}),n(V,{size:"md",class:"py-3",label:"Smart memory",description:"When disabled forces ComfyUI to aggressively offload to regular RAM instead of keeping models in VRAM when it can."},{default:a(()=>[n(T,{modelValue:t(d).settingsMap.smart_memory.value,"onUpdate:modelValue":e[0]||(e[0]=l=>t(d).settingsMap.smart_memory.value=l),color:"primary",class:"py-3",label:"Enable smart memory"},null,8,["modelValue"])]),_:1}),n(V,{size:"md",class:"py-3",label:"Cache type"},{description:a(()=>e[19]||(e[19]=[i("p",null,[r(" Classic - Use the old style (aggressive) caching. "),i("br"),r(" LRU - Use LRU caching with a maximum of N node results cached. May use more RAM/VRAM. "),i("br"),r(" None - Reduced RAM/VRAM usage at the expense of executing every node for each run. "),i("br")],-1)])),default:a(()=>[i("div",Le,[n(B,{modelValue:t(d).settingsMap.cache_type.value,"onUpdate:modelValue":e[1]||(e[1]=l=>t(d).settingsMap.cache_type.value=l),class:"w-fit",placeholder:"Select cache type","value-attribute":"value",options:t(d).settingsMap.cache_type.options},null,8,["modelValue","options"])]),t(d).settingsMap.cache_type.value==="lru"?(u(),_($,{key:0,modelValue:t(d).settingsMap.cache_size.value,"onUpdate:modelValue":e[2]||(e[2]=l=>t(d).settingsMap.cache_size.value=l),type:"number",class:"w-fit",min:"1",onChange:e[3]||(e[3]=()=>{t(d).settingsMap.cache_size.value=t(d).settingsMap.cache_size.value.toString()})},null,8,["modelValue"])):m("",!0)]),_:1}),n(V,{size:"md",class:"py-3",label:"VAE cpu",description:"Run the VAE on the CPU."},{default:a(()=>[n(T,{modelValue:t(d).settingsMap.vae_cpu.value,"onUpdate:modelValue":e[4]||(e[4]=l=>t(d).settingsMap.vae_cpu.value=l),color:"primary",class:"py-3",label:"VAE on CPU"},null,8,["modelValue"])]),_:1}),n(p,{class:"mt-3",icon:"i-heroicons-check-16-solid",loading:t(P),onClick:te},{default:a(()=>e[20]||(e[20]=[r(" Save ")])),_:1},8,["loading"])])):m("",!0),n(I,{class:"my-3"}),i("div",Oe,[i("div",Pe,[n(B,{modelValue:t(U),"onUpdate:modelValue":e[5]||(e[5]=l=>A(U)?U.value=l:null),class:"mr-3",options:t(S),multiple:""},null,8,["modelValue","options"]),n($,{modelValue:t(C),"onUpdate:modelValue":e[6]||(e[6]=l=>A(C)?C.value=l:null),placeholder:"Filter workers..."},null,8,["modelValue"])]),t(g).length>=1?(u(),w("div",Ie,[n(B,{modelValue:t(y),"onUpdate:modelValue":e[7]||(e[7]=l=>A(y)?y.value=l:null),searchable:"",class:"mr-3 my-3 lg:mx-3 lg:my-0 w-full max-w-64 min-w-64",options:t(L),multiple:""},{label:a(()=>[i("span",null,"Tasks to give ("+c(t(Q))+")",1)]),_:1},8,["modelValue","options"]),n(ae,{text:"Flows available for worker to get tasks"},{default:a(()=>[n(p,{icon:"i-heroicons-check-16-solid",variant:"outline",color:"cyan",size:"sm",loading:t(z),onClick:Z},{default:a(()=>e[21]||(e[21]=[r(" Update tasks to give ")])),_:1},8,["loading"])]),_:1}),n(p,{icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[8]||(e[8]=()=>{y.value=[]})})])):m("",!0)]),n(se,{modelValue:t(M),"onUpdate:modelValue":e[17]||(e[17]=l=>A(M)?M.value=l:null),transition:!1},{default:a(()=>{var l;return[i("div",$e,[e[25]||(e[25]=i("h2",{class:"font-bold"},"Individual worker configuration options",-1)),i("p",Ge,c((l=t(s))==null?void 0:l.worker_id),1),t(s)?(u(),w("div",je,[n(V,{size:"md",class:"py-3",label:"Smart memory",description:"When disabled forces ComfyUI to aggressively offload to regular RAM instead of keeping models in VRAM when it can."},{default:a(()=>[t(s).smart_memory===null?(u(),_(W,{key:0,color:"cyan",variant:"soft",title:"Not set",class:"mb-2"})):m("",!0),i("div",Ye,[n(T,{modelValue:t(s).smart_memory,"onUpdate:modelValue":e[9]||(e[9]=f=>t(s).smart_memory=f),color:"primary",class:"py-3",label:"Enable smart memory"},null,8,["modelValue"]),t(s).smart_memory?(u(),_(p,{key:0,icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[10]||(e[10]=()=>{t(s)&&(t(s).smart_memory=null)})})):m("",!0)])]),_:1}),n(V,{size:"md",class:"py-3",label:"Cache type"},{description:a(()=>e[22]||(e[22]=[i("p",null,[r(" Classic - Use the old style (aggressive) caching. "),i("br"),r(" LRU - Use LRU caching with a maximum of N node results cached. May use more RAM/VRAM. "),i("br"),r(" None - Reduced RAM/VRAM usage at the expense of executing every node for each run. "),i("br")],-1)])),default:a(()=>[t(s).cache_type===null?(u(),_(W,{key:0,color:"cyan",variant:"soft",title:"Not set",class:"mb-2"})):m("",!0),i("div",qe,[n(B,{modelValue:t(s).cache_type,"onUpdate:modelValue":e[11]||(e[11]=f=>t(s).cache_type=f),class:"w-fit",placeholder:"Select cache type","value-attribute":"value",options:t(d).settingsMap.cache_type.options},null,8,["modelValue","options"]),t(s).cache_type!==null?(u(),_(p,{key:0,icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[12]||(e[12]=()=>{t(s)&&(t(s).cache_type=null)})})):m("",!0)]),t(s).cache_type==="lru"&&t(s).cache_size===null?(u(),_(W,{key:1,color:"cyan",variant:"soft",title:"Not set",class:"mb-2"})):m("",!0),t(s).cache_type==="lru"?(u(),w("div",Je,[n($,{modelValue:t(s).cache_size,"onUpdate:modelValue":e[13]||(e[13]=f=>t(s).cache_size=f),type:"number",class:"w-fit",min:"1"},null,8,["modelValue"]),t(s).cache_size!==null?(u(),_(p,{key:0,icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[14]||(e[14]=()=>{t(s)&&(t(s).cache_size=null)})})):m("",!0)])):m("",!0)]),_:1}),n(V,{size:"md",class:"py-3",label:"VAE cpu",description:"Run the VAE on the CPU."},{default:a(()=>[t(s).vae_cpu===null?(u(),_(W,{key:0,color:"cyan",variant:"soft",title:"Not set",class:"mb-2"})):m("",!0),i("div",He,[n(T,{modelValue:t(s).vae_cpu,"onUpdate:modelValue":e[15]||(e[15]=f=>t(s).vae_cpu=f),color:"primary",class:"py-3",label:"VAE on CPU"},null,8,["modelValue"]),t(s).vae_cpu?(u(),_(p,{key:0,icon:"i-heroicons-x-mark",variant:"outline",color:"white",class:"ml-2",onClick:e[16]||(e[16]=()=>{t(s)&&(t(s).vae_cpu=null)})})):m("",!0)])]),_:1})])):m("",!0),i("div",Ke,[n(p,{class:"mr-2",variant:"solid",color:"green",loading:t(z),onClick:oe},{default:a(()=>e[23]||(e[23]=[r(" Save ")])),_:1},8,["loading"]),n(p,{class:"mr-2",variant:"solid",color:"white",onClick:J},{default:a(()=>e[24]||(e[24]=[r(" Cancel ")])),_:1})])])]}),_:1},8,["modelValue"]),n(ie,{modelValue:t(g),"onUpdate:modelValue":e[18]||(e[18]=l=>A(g)?g.value=l:null),columns:t(U),rows:t(C)===""?t(O):t(X),loading:t(b).$state.loading},{"actions-data":a(({row:l})=>[n(p,{icon:"i-heroicons-pencil-16-solid",variant:"outline",color:"cyan",size:"sm",onClick:()=>{le(l)}},{default:a(()=>e[26]||(e[26]=[r(" Edit ")])),_:2},1032,["onClick"])]),"worker_status-data":a(({row:l})=>[n(h,{variant:"solid",color:Y(l)==="Online"?"green":"red"},{default:a(()=>[r(c(Y(l)),1)]),_:2},1032,["color"])]),"federated-data":a(({row:l})=>[n(h,{variant:"solid",color:l.federated_instance_name!==""?"blue":"green"},{default:a(()=>[r(c(l.federated_instance_name!==""?"Yes":"No"),1)]),_:2},1032,["color"])]),"busy-data":a(({row:l})=>[n(h,{variant:"solid",color:l.empty_task_requests_count===0?"red":"green"},{default:a(()=>[r(c(l.empty_task_requests_count===0?"Yes":"No"),1)]),_:2},1032,["color"])]),"tasks_to_give-data":a(({row:l})=>[l.tasks_to_give.length===0?(u(),w("span",Qe,"All")):(u(),_(re,{key:1,popper:{placement:"bottom"}},{panel:a(()=>[i("div",Ze,[(u(!0),w(ze,null,Te(l.tasks_to_give,f=>(u(),_(h,{key:f,class:"mr-2 mb-2",variant:"solid",color:"cyan"},{default:a(()=>[n(ne,{class:"hover:underline",to:`/workflows/${f}`},{default:a(()=>[r(c(f),1)]),_:2},1032,["to"])]),_:2},1024))),128))])]),default:a(()=>[n(p,{icon:"i-heroicons-list-bullet-16-solid",variant:"outline",color:"gray",size:"sm"},{default:a(()=>[i("span",null,c(l.tasks_to_give.length)+" selected",1)]),_:2},1024)]),_:2},1024))]),"last_seen-data":a(({row:l})=>[r(c(new Date(l.last_seen).toLocaleString()),1)]),"vram_total-data":a(({row:l})=>[r(c(("formatBytes"in o?o.formatBytes:t(x))(l.vram_total)),1)]),"vram_free-data":a(({row:l})=>[r(c(("formatBytes"in o?o.formatBytes:t(x))(l.vram_free)),1)]),"torch_vram_total-data":a(({row:l})=>[r(c(("formatBytes"in o?o.formatBytes:t(x))(l.torch_vram_total)),1)]),"torch_vram_free-data":a(({row:l})=>[r(c(("formatBytes"in o?o.formatBytes:t(x))(l.torch_vram_free)),1)]),"ram_total-data":a(({row:l})=>[r(c(("formatBytes"in o?o.formatBytes:t(x))(l.ram_total)),1)]),"ram_free-data":a(({row:l})=>[r(c(("formatBytes"in o?o.formatBytes:t(x))(l.ram_free)),1)]),"smart_memory-data":a(({row:l})=>[n(h,{variant:"solid",color:l.smart_memory?"green":"red"},{default:a(()=>[r(c(l.smart_memory?"Yes":"No"),1)]),_:2},1032,["color"])]),"cache_type-data":a(({row:l})=>[n(h,{variant:"solid",color:l.cache_type==="none"?"red":"green"},{default:a(()=>[r(c(l.cache_type??t(d).settingsMap.cache_type.value),1)]),_:2},1032,["color"])]),"cache_size-data":a(({row:l})=>[r(c(l.cache_size&&l.cache_type==="lru"?l.cache_size+" nodes":"N/A"),1)]),"vae_cpu-data":a(({row:l})=>[n(h,{variant:"solid",color:l.vae_cpu?"green":"red"},{default:a(()=>[r(c(l.vae_cpu?"Yes":"No"),1)]),_:2},1032,["color"])]),_:1},8,["modelValue","columns","rows","loading"])])])]),_:1})}}});export{rt as default};
